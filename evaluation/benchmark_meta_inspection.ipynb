{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e7eda1d",
   "metadata": {},
   "source": [
    "# Benchmark Meta Inspection\n",
    "This notebook prints some statistics about the benchmark. Swap the file path from `50000006_german.jsonl` to `50000006_german_template.jsonl` depending on whether you want statistics about the parameterized questions or the instantiations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590cbf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "script_dir = os.path.abspath(\"\")\n",
    "file_path = os.path.join(script_dir, \"../data/evaluation\", \"50000006_german.jsonl\")\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "answer_types = []\n",
    "dataset_lists = []\n",
    "step_lists = []\n",
    "\n",
    "for i, line in enumerate(lines):\n",
    "    try:\n",
    "        data = json.loads(line)\n",
    "        answer_types.append(data[\"answer_type\"])\n",
    "        dataset_lists.append(data[\"outputs\"][\"relevant_datasets\"])\n",
    "        if \"required_operations\" in data:\n",
    "            step_lists.append(data[\"required_operations\"])\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "# Count how common each number of datasets is\n",
    "dataset_counts = {}\n",
    "for datasets in dataset_lists:\n",
    "    num_datasets = len(datasets)\n",
    "    if num_datasets not in dataset_counts:\n",
    "        dataset_counts[num_datasets] = 0\n",
    "    dataset_counts[num_datasets] += 1\n",
    "\n",
    "# Print number of positive (more than 0 datasets) and negative (0 datasets) questions\n",
    "positive_count = sum(1 for datasets in dataset_lists if len(datasets) > 0)\n",
    "negative_count = sum(1 for datasets in dataset_lists if len(datasets) == 0)\n",
    "print(f\"{positive_count} positive questions and {negative_count} negative questions.\")\n",
    "\n",
    "print(\"\\nNumber of datasets counts:\")\n",
    "for num_datasets, count in sorted(dataset_counts.items()):\n",
    "    print(f\"{num_datasets} datasets: {count}\")\n",
    "\n",
    "# Figure out number of unique datasets\n",
    "unique_datasets = set()\n",
    "for datasets in dataset_lists:\n",
    "    unique_datasets.update(datasets)\n",
    "print(f\"\\nNumber of unique datasets: {len(unique_datasets)}\")\n",
    "\n",
    "# Print how often each answer type appears\n",
    "answer_type_counts = {answer_type: answer_types.count(answer_type) for answer_type in set(answer_types)}\n",
    "print(\"\\nAnswer type counts:\")\n",
    "for answer_type, count in sorted(answer_type_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{answer_type}: {count}\")\n",
    "\n",
    "# See how many questions require how many operations\n",
    "operation_counts = {}\n",
    "for steps in step_lists:\n",
    "    num_operations = len(steps)\n",
    "    if num_operations not in operation_counts:\n",
    "        operation_counts[num_operations] = 0\n",
    "    operation_counts[num_operations] += 1\n",
    "\n",
    "print(\"\\nNumber of operations counts:\")\n",
    "for num_operations, count in sorted(operation_counts.items()):\n",
    "    print(f\"{num_operations} operations: {count}\")\n",
    "\n",
    "# Concat all steps into one list and see how often each step appears\n",
    "all_steps = []\n",
    "for steps in step_lists:\n",
    "    all_steps.extend(steps)\n",
    "step_counts = {step: all_steps.count(step) for step in set(all_steps)}\n",
    "print(\"\\nStep counts:\")\n",
    "for step, count in sorted(step_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{step}: {count}\")\n",
    "\n",
    "\n",
    "# Count how many times each category appears in template, as category field not present in actual benchmark\n",
    "file_path_template = os.path.join(script_dir, \"../data/evaluation\", \"50000006_german_template.jsonl\")\n",
    "\n",
    "with open(file_path_template, \"r\", encoding=\"utf-8\") as file:\n",
    "    template_lines = file.readlines()\n",
    "\n",
    "category_counts = {}\n",
    "for i, line in enumerate(template_lines):\n",
    "    data = json.loads(line)\n",
    "    if \"dataset_categories\" in data:\n",
    "        categories = data[\"dataset_categories\"]\n",
    "        for category in categories:\n",
    "            if category not in category_counts:\n",
    "                category_counts[category] = 0\n",
    "            category_counts[category] += min(4, len(data.get(\"param_options\", [\"\"])))\n",
    "\n",
    "print(\"\\nCategory counts:\")\n",
    "for category, count in sorted(category_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{category}: {count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
